{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional GAN\n",
    "\n",
    "**Purpose**: This notebook provides a walk through the process of training a Conditional GAN to generate digits on the MNIST dataset. Refer to the paper https://arxiv.org/abs/1411.1784 for a full detailed explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.pylab import plt\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PARAMETERS = {'batch_size': 128,\n",
    "                    'num_classes': 10,\n",
    "                    'img_shape': (1,28,28),\n",
    "                    'epochs': 200,\n",
    "                    'learning_rate': 0.0002}\n",
    "\n",
    "MODEL_HYPERPARAMETERS = {'generator_latent_dim': 100}\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size,\n",
    "                   img_shape):\n",
    "    \n",
    "    img_size = img_shape[1:]\n",
    "    \n",
    "    dataset = datasets.MNIST(root='./data/MNIST',\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transforms.Compose([transforms.Resize(img_size),\n",
    "                                                           transforms.ToTensor(),\n",
    "                                                           transforms.Normalize([0.5], [0.5])]))\n",
    "    \n",
    "    return torch.utils.data.DataLoader(dataset,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(TRAIN_PARAMETERS['batch_size'],\n",
    "                            TRAIN_PARAMETERS['img_shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Nets consist on two components competing against each other in a min-max game. These models are:\n",
    "\n",
    "- The **Generator:** Captures the data distribution and tries to generate realistic samples accordingly.\n",
    "- The **Discriminator:** Estimates the probability of a sample of data as being real or created by the Generator.\n",
    "\n",
    "Both models play a min max game; the objective of the generator is to fool the discriminator by generating more realistic samples. On the other hand, the discriminator's objective is to identify the samples created by the generator.\n",
    "\n",
    "The input of the **Generator** is typically a noise vector **z**, as to create variety in the generated samples.\n",
    "\n",
    "The input of the **Discriminator** is a sample of data **x**, which can be a real sample or a generated sample.\n",
    "\n",
    "Translating these min max game to mathematics, we adjust the Generator's parameters to minimize $log(1-D(G(z))$ and the Discriminator's parameters to minimize $log(D(x))$. Thus, resulting in the following formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/gan_training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Conditional GAN** framework adds to both, the input of the discriminator and the generator, some extra information **y** (note that the aforementioned formula will need to include the condition on **y**). \n",
    "\n",
    "This extra information represent the class of the sample. It will guide the Generator in its creation and help the Discriminator in its prediction.\n",
    "\n",
    "The model architecture is depicted in the next figure. As it can be seen in the Figure, the generator concatenates the sampling from **z** with the input **y**. Likewise, the discriminator concatenates **x** with the input **y**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/conditional_gan_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 img_shape,\n",
    "                 latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        self.img_shape = img_shape\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=False):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim + n_classes, 256, normalize=False),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(n_classes,\n",
    "                                            n_classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_classes + int(np.prod(img_shape)), 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_model(num_classes,\n",
    "                        img_shape,\n",
    "                        latent_dim,\n",
    "                        lr,\n",
    "                        device):\n",
    "    ''' Returns the generator model and its optimizer '''\n",
    "    \n",
    "    generator = Generator(num_classes,\n",
    "                          img_shape,\n",
    "                          latent_dim)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(generator.parameters(),\n",
    "                                 lr=lr)\n",
    "    \n",
    "    return generator.to(device), optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator_model(num_classes,\n",
    "                            img_shape,\n",
    "                            lr,\n",
    "                            device):\n",
    "    ''' Returns the discriminator model and its optimizer '''\n",
    "    \n",
    "    discriminator = Discriminator(num_classes,\n",
    "                                  img_shape)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(discriminator.parameters(),\n",
    "                                 lr=lr)\n",
    "    \n",
    "    return discriminator.to(device), optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, optimizer_G = get_generator_model(TRAIN_PARAMETERS['num_classes'],\n",
    "                                             TRAIN_PARAMETERS['img_shape'],\n",
    "                                             MODEL_HYPERPARAMETERS['generator_latent_dim'],\n",
    "                                             TRAIN_PARAMETERS['learning_rate'],\n",
    "                                             DEVICE)\n",
    "discriminator, optimizer_D = get_discriminator_model(TRAIN_PARAMETERS['num_classes'],\n",
    "                                                     TRAIN_PARAMETERS['img_shape'],\n",
    "                                                     TRAIN_PARAMETERS['learning_rate'],\n",
    "                                                     DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adversarial_loss():\n",
    "    ''' Returns the adversarial loss '''\n",
    "    \n",
    "    return torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = get_adversarial_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "As mentioned earlier, the training of the model is an **adversarial process** in which the Generator and the Discriminator are trained simultaneously.\n",
    "\n",
    "The adversarial nature of the process is due to the fact that the Discriminator is trained to distinguish between real data and fake data, therefore, to recognize the Generator's flaws while the Generator is trained to fool the Discriminator with its generated samples.\n",
    "\n",
    "Nonetheless, this process is **highly unstable**. Some of the problems that may occur are:\n",
    "\n",
    "- **Vanishing gradients**: When the Discriminator gets too good, its loss becomes very close to 0, which blocks the gradient to flow into the generator and prevents it to learn.\n",
    "- **Mode collapse**: It is sometimes possible that the Generator find specific samples that can fool the Discriminator all the time. When this happens, the Generator starts to create only these samples, and looses its variety.\n",
    "- **Failure to converge**: If the Loss function is not well designed or the weights update are too large, the two models might not converge to any good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reconstruction(generator,\n",
    "                        generator_latent_dim,\n",
    "                        n_row,\n",
    "                        epoch_n,\n",
    "                        device):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "\n",
    "    # Create the saving directory\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    # Sample noise\n",
    "    z = torch.FloatTensor(np.random.normal(0, 1, (n_row ** 2, generator_latent_dim))).to(device)\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, \"results/%d.png\" % epoch_n, nrow=n_row, normalize=True)\n",
    "    \n",
    "    return plt.imread(\"results/%d.png\" % epoch_n)\n",
    "\n",
    "def init_figure():\n",
    "    \"\"\"Init interactive figure with 3 subplots for the notebook graphics\"\"\"\n",
    "    fig = plt.figure(figsize=(10, 12))\n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax3 = fig.add_subplot(212)\n",
    "\n",
    "    return fig, (ax1, ax2, ax3)\n",
    "\n",
    "\n",
    "def plot_current_results(image, model_loss, fig, axes):\n",
    "    \"\"\"Use the visuals dict to fill the fig and axes\"\"\"\n",
    "    ax1, ax2, ax3 = axes\n",
    "\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    ax3.clear()\n",
    "\n",
    "    epochs = range(1, len(model_loss['generator'])+1)\n",
    "    \n",
    "    ax1.plot(epochs, model_loss['generator'])\n",
    "    ax1.set_title('Generator Loss')\n",
    "\n",
    "    ax2.plot(epochs, model_loss['discriminator'])\n",
    "    ax2.set_title('Discriminator Loss')\n",
    "\n",
    "    ax3.imshow(image)\n",
    "    ax3.set_xticks([])\n",
    "    ax3.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_dict):\n",
    "    ''' Plots the loss evolution of the discriminator and generator '''\n",
    "    \n",
    "    for component_name, component_loss in loss_dict.items():\n",
    "        \n",
    "        plt.plot(component_loss, label=component_name)\n",
    "    \n",
    "    plt.title('Loss plot')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise:\n",
    "\n",
    "- As an exercise, try to complete the code for computing the loss of both the discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs,\n",
    "                dataloader,\n",
    "                generator,\n",
    "                optimizer_G,\n",
    "                discriminator,\n",
    "                optimizer_D,\n",
    "                adv_loss,\n",
    "                generator_latent_dim,\n",
    "                n_classes,\n",
    "                device):\n",
    "    ''' Trains the GAN model '''\n",
    "    \n",
    "    model_loss = {'generator': [], 'discriminator': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        running_g_loss = running_d_loss = 0\n",
    "        \n",
    "        for x, y in dataloader:\n",
    "            \n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            batch_size = x.shape[0]\n",
    "            \n",
    "            valid = torch.FloatTensor(batch_size, 1).fill_(1.0).to(device)\n",
    "            fake = torch.FloatTensor(batch_size, 1).fill_(0.0).to(device)\n",
    "        \n",
    "            \n",
    "            ## -------------------\n",
    "            ## Train discriminator\n",
    "            ## -------------------\n",
    "            \n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            z = torch.FloatTensor(np.random.normal(0, 1, (batch_size, generator_latent_dim))).to(device)\n",
    "            gen_y = torch.LongTensor(np.random.randint(0, n_classes, batch_size)).to(device)\n",
    "            gen_x = generator(z, gen_y)\n",
    "            \n",
    "            validity_fake = ... # Implement me!\n",
    "            validity_real = ... # Implement me!\n",
    "            d_real_loss = ... # Implement me!\n",
    "            d_fake_loss = ... # Implement me!\n",
    "            \n",
    "            d_loss = ... # Implement me!\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            ## ---------------\n",
    "            ## Train generator\n",
    "            ## ---------------\n",
    "            \n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Sample noise and labels\n",
    "            z = torch.FloatTensor(np.random.normal(0, 1, (batch_size, generator_latent_dim))).to(device)\n",
    "            gen_y = torch.LongTensor(np.random.randint(0, n_classes, batch_size)).to(device)\n",
    "            gen_x = generator(z, gen_y)\n",
    "\n",
    "            validity = ... # Implement me!\n",
    "            g_loss = ... # Implement me!\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            running_g_loss += g_loss.item()\n",
    "            \n",
    "            running_d_loss += d_loss.item()\n",
    "            \n",
    "        epoch_g_loss = running_g_loss / len(dataloader)\n",
    "        epoch_d_loss = running_d_loss / len(dataloader)\n",
    "        \n",
    "        print('G Loss: {:.4f} D Loss: {:.4f}'.format(epoch_g_loss,\n",
    "                                                     epoch_d_loss))\n",
    "        \n",
    "        model_loss['generator'].append(epoch_g_loss)\n",
    "        model_loss['discriminator'].append(epoch_d_loss)\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            generator.eval()\n",
    "\n",
    "            image = save_reconstruction(generator,\n",
    "                                generator_latent_dim,\n",
    "                                n_classes,\n",
    "                                epoch,\n",
    "                                device)\n",
    "            fig, axs = init_figure()\n",
    "            plot_current_results(image, model_loss, fig, axs)\n",
    "            generator.train()\n",
    "    \n",
    "    plot_loss(model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_model(TRAIN_PARAMETERS['epochs'],\n",
    "            dataloader,\n",
    "            generator,\n",
    "            optimizer_G,\n",
    "            discriminator,\n",
    "            optimizer_D,\n",
    "            adversarial_loss,\n",
    "            MODEL_HYPERPARAMETERS['generator_latent_dim'],\n",
    "            TRAIN_PARAMETERS['num_classes'],\n",
    "            DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just implemented a Conditional GAN using the Binary Cross Entropy loss! \n",
    "\n",
    "GANs are an intensely studied topic nowadays, and scientists have designed a lot of different versions of GANs. One of them in particular, called [LSGAN](https://arxiv.org/abs/1611.04076) will be of interests for the future of the workshop.\n",
    "\n",
    "Without going into details now, the particularity of LSGAN is the use of Mean Squared Error Loss instead of the Binary Cross Entropy Loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "\n",
    "- As an exercise, implement LSGAN by substituting the Binary Cross Entropy with Mean Squared Error Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = ... #Implement me!\n",
    "train_model(TRAIN_PARAMETERS['epochs'],\n",
    "             dataloader,\n",
    "             generator,\n",
    "             optimizer_G,\n",
    "             discriminator,\n",
    "             optimizer_D,\n",
    "             adversarial_loss,\n",
    "             MODEL_HYPERPARAMETERS['generator_latent_dim'],\n",
    "             TRAIN_PARAMETERS['num_classes'],\n",
    "             DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
