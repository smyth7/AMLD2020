{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmium\n",
    "import shapely.wkb as wkblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rtree import index\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new-york-latest.osm.pbf\n",
    "\n",
    "class RouteAnnotator(osmium.SimpleHandler):\n",
    "\n",
    "    def __init__(self, pbf_path, bbox=None):\n",
    "        \"\"\"\n",
    "        pbf_path: osm.pbf file path\n",
    "        bbox: array[2] - [[lat, lon] bottom_left, [lat, lon] upper_right]\n",
    "        \"\"\"\n",
    "        osmium.SimpleHandler.__init__(self)\n",
    "        \n",
    "        self.ROAD_TYPES = ['motorway', 'trunk', 'primary', 'secondary', 'tertiary', 'road', 'residential', 'service',\n",
    "                           'motorway_link', 'trunk_link', 'primary_link', 'secondary_link', 'tertiary_link']\n",
    "        self.GEOMETRY_NAME = 'line'\n",
    "        \n",
    "        self.wkbfab = osmium.geom.WKBFactory()\n",
    "        self.df = []\n",
    "        self.r_tree = None\n",
    "        \n",
    "        self.apply_file(pbf_path, locations=True)\n",
    "        \n",
    "        self.build_dataframe()\n",
    "        \n",
    "    def way(self, elem):\n",
    "        #  elem.nodes return a node list:\n",
    "        # https://docs.osmcode.org/pyosmium/latest/ref_osm.html?highlight=noderef#osmium.osm.NodeRef\n",
    "\n",
    "        # TagList can't be converted to dict automatically, see:\n",
    "        # https://github.com/osmcode/pyosmium/issues/106\n",
    "        keys = {tag.k: tag.v for tag in elem.tags}\n",
    "        # filter all types of car driving highways: https://wiki.openstreetmap.org/wiki/Key:highway?uselang=en-GBs\n",
    "        if (('highway' in keys.keys())):\n",
    "            if (keys['highway'] in self.ROAD_TYPES):\n",
    "                nodes = [n.ref for n in elem.nodes]\n",
    "                wkb = self.wkbfab.create_linestring(elem)\n",
    "                line = wkblib.loads(wkb, hex=True)\n",
    "                names = [el.v for el in elem.tags if el.k == 'name']\n",
    "                maxspeeds = [el.v for el in elem.tags if el.k == 'maxspeed']\n",
    "                highway_type = [el.v for el in elem.tags if el.k == 'highway']\n",
    "\n",
    "                self.df.append([elem.id,\n",
    "                                nodes,\n",
    "                                line.length,\n",
    "                                names[0] if len(names) > 0 else '',\n",
    "                                maxspeeds[0] if len(maxspeeds) > 0 else np.nan,\n",
    "                                highway_type,\n",
    "                                line])\n",
    "        \n",
    "    def build_dataframe(self):\n",
    "        cols = ['way_id', 'nodes', 'line_length', 'name', 'maxspeed', 'highway_type', self.GEOMETRY_NAME]\n",
    "        self.df = pd.DataFrame(self.df, columns=cols)\n",
    "        self.df['highway_type'] = [e[0] for e in self.df['highway_type']]\n",
    "        not_numeric_flag = ~self.df['maxspeed'].astype(str).str.isnumeric()\n",
    "        self.df.loc[not_numeric_flag, 'maxspeed'] = '0'\n",
    "        self.df['maxspeed'] = self.df['maxspeed'].astype(int)\n",
    "        self.df = gpd.GeoDataFrame(self.df, geometry=self.df[self.GEOMETRY_NAME]).reset_index()\n",
    "        \n",
    "        HIGHWAY_SPEED_LIMITS ={   # copied from https://github.com/Project-OSRM/osrm-backend/blob/master/profiles/car.lua\n",
    "            'motorway':90,\n",
    "            'motorway_link':45,\n",
    "            'trunk':85,\n",
    "            'trunk_link':40,\n",
    "            'primary':65,\n",
    "            'primary_link':30,\n",
    "            'secondary':55,\n",
    "            'secondary_link':25,\n",
    "            'tertiary':40,\n",
    "            'tertiary_link':20,\n",
    "            'unclassified':25,\n",
    "            'residential':25,\n",
    "            'living_street':10,\n",
    "            'service':15,\n",
    "            'footway': 4,    # custom\n",
    "            'path': 4,       # \n",
    "            'pedestrian': 4, # \n",
    "            'steps': 2,      #\n",
    "            'track': 4,      #   \n",
    "            'piste': 4,      #\n",
    "            'corridor': 4,   #\n",
    "            'bridleway': 4,  #   \n",
    "            'razed': 4,      #  \n",
    "            'elevator': 0.2  #  \n",
    "        }\n",
    "\n",
    "        speeds_df = pd.DataFrame({'highway_type': [elem for elem in HIGHWAY_SPEED_LIMITS.keys()],\n",
    "                      'highway_speed': [elem for elem in HIGHWAY_SPEED_LIMITS.values()]})\n",
    "\n",
    "        self.df = self.df.merge(speeds_df,\n",
    "                         how='left',\n",
    "                         left_on='highway_type',\n",
    "                         right_on='highway_type')\n",
    "        \n",
    "#         self.df = self.df.drop('maxspeed', axis=1)\n",
    "     \n",
    "    def apply_bbox(self, bbox):\n",
    "        \"\"\"\n",
    "        bbox: array[[lat, lon] bottom left, [lat, lon] upper right]\n",
    "        example: \n",
    "        \n",
    "        b_l = [40.498266, -74.270820]\n",
    "        u_r = [40.915519, -73.680854]\n",
    "        \n",
    "        bbox = [b_l, u_r]\n",
    "        \n",
    "        bbox = Polygon([[bbox[0][1],bbox[0][0]], \n",
    "                         [bbox[1][1],bbox[0][0]],\n",
    "                         [bbox[1][1],bbox[1][0]],\n",
    "                         [bbox[0][1],bbox[1][0]]])\n",
    "                         \n",
    "        route_annotator.apply_bbox(bbox)\n",
    "        \"\"\"\n",
    "\n",
    "        bbox = Polygon([[bbox[0][1],bbox[0][0]], \n",
    "                         [bbox[1][1],bbox[0][0]],\n",
    "                         [bbox[1][1],bbox[1][0]],\n",
    "                         [bbox[0][1],bbox[1][0]]])\n",
    "\n",
    "        self.df = self.df.loc[self.df.intersects(bbox)].copy()\n",
    "        \n",
    "    def create_spatial_index(self):\n",
    "        # Populate R-tree index with bounds of grid cells\n",
    "        self.r_tree = index.Index()\n",
    "        pols = []\n",
    "        for way_id, row in self.df.iterrows():\n",
    "            p = Polygon(row[self.GEOMETRY_NAME].buffer(.00005).exterior.coords)\n",
    "            p.maxspeed = row['maxspeed']\n",
    "            p.way_id = way_id\n",
    "            p.name = row['name']\n",
    "            pols.append(p)\n",
    "\n",
    "            self.r_tree.insert(way_id, p.bounds) \n",
    "            \n",
    "    # TODO: optmize removal by using r-tree and checking repetitive points only at neighborhood level\n",
    "    def drop_duplicate_way_id_nodes(self):\n",
    "\n",
    "        node_pair = {}\n",
    "        way_id_1 = []\n",
    "        way_id_2 = []\n",
    "\n",
    "        for ix, row in self.df.iterrows():             # for each array from a way_id\n",
    "            ix = 1\n",
    "            while(ix < len(row['nodes'])):        # while we don't run trought all elements from array    \n",
    "                node_pre = row['nodes'][ix-1]     # dict: key = node_pre, value = [[nodes_post][nodes_post_way_id]]\n",
    "                node_post = row['nodes'][ix]\n",
    "                if(node_pre in node_pair.keys()):                       # if node_pre is in keys\n",
    "                    if(node_post in node_pair[node_pre][0]):               # check list of nodes_post. If node_post is there\n",
    "                        way_id_1.append(node_pair[node_pre][1][node_post]) # it means a rep node_ids. \n",
    "                        way_id_2.append(row['way_id'])                     # Store the way_id pre and post\n",
    "                    else:\n",
    "                        node_pair[node_pre][0].append(node_post)           # if nodes_post in not in values\n",
    "                        node_pair[node_pre][1][node_post] = row['way_id']  # store relation in the dictionary\n",
    "\n",
    "                else:                                                   # if node_pre is NOT in keys \n",
    "                    node_pair[node_pre] = [[node_post], {node_post:row['way_id']}] # create node_pre array structure\n",
    "                ix += 1\n",
    "\n",
    "        repetitive_ways = pd.DataFrame({'way_id_1': way_id_1, 'way_id_2':way_id_2})\n",
    "\n",
    "        print(f'number of ways if sharing nodes: {repetitive_ways.shape[0]}')\n",
    "\n",
    "\n",
    "        ### get way_id_1 and 2's line length\n",
    "        repetitive_ways_1 = repetitive_ways.merge(self.df[['way_id', 'line_length']],\n",
    "                              how='left',\n",
    "                              left_on='way_id_1',\n",
    "                              right_on='way_id')\n",
    "\n",
    "        repetitive_ways_1 = repetitive_ways_1.merge(self.df[['way_id', 'line_length']],\n",
    "                              how='left',\n",
    "                              left_on='way_id_2',\n",
    "                              right_on='way_id')\n",
    "\n",
    "        repetitive_ways_1.head()\n",
    "\n",
    "        # retrieve way_id that has smaller length and remove\n",
    "        smaller_repetitive = [row['way_id_1'] if row['line_length_x'] <= row['line_length_y'] else row['way_id_2'] for ix, row in repetitive_ways_1.iterrows()]\n",
    "        smaller_repetitive = np.array(smaller_repetitive).astype(int)\n",
    "\n",
    "        self.df = self.df.loc[self.df['way_id'].isin(smaller_repetitive)].copy()            \n",
    "\n",
    "#     def get_street_max_speed(self, segment):\n",
    "#     # rank 7, segment LINESTRING (13.28866358846426 52.45759948794097, 13.28908503055573 52.45704031539945)\n",
    "#     # fails because of lack of precision, check out here http://arthur-e.github.io/Wicket/sandbox-gmaps3.html\n",
    "#     # Need mapmatch\n",
    "#     # Filter possible candidates using R-Tree\n",
    "#         idxs = list(self.r_tree.intersection(segment.bounds))\n",
    "#         if (len(idxs) > 0):\n",
    "#             # Now do actual intersection\n",
    "#             filter1 = self.df.loc[idxs].contains(segment)\n",
    "#             way_id = self.df.loc[filter1[filter1 == True].index]\n",
    "#             if (len(way_id) > 0):\n",
    "#                 way_id = way_id['line_length'].idxmin()\n",
    "#                 return self.df.loc[way_id]['maxspeed']\n",
    "#             else:\n",
    "#                 first_point = Point(segment.xy[0][0], segment.xy[1][0])\n",
    "#                 idxs = list(self.r_tree.intersection(first_point.bounds))\n",
    "#                 if (len(idxs) > 0):\n",
    "#                     filter1 = self.df.loc[idxs].contains(first_point)\n",
    "#                     if (np.sum(filter1) > 0):\n",
    "#                         way_id = self.df.loc[filter1[filter1 == True].index]['line_length'].idxmin()\n",
    "#                         return self.df.loc[way_id]['maxspeed']\n",
    "\n",
    "#                 second_point = Point(segment.xy[0][1], segment.xy[1][1])\n",
    "#                 idxs = list(self.r_tree.intersection(second_point.bounds))\n",
    "#                 if (len(idxs) > 0):\n",
    "#                     filter1 = self.df.loc[idxs].contains(second_point)\n",
    "#                     if (np.sum(filter1) > 0):\n",
    "#                         way_id = self.df.loc[filter1[filter1 == True].index]['line_length'].idxmin()\n",
    "#                         return self.df.loc[way_id]['maxspeed']\n",
    "#         raise Exception(\n",
    "#             f'Error mapping segment {segment} to street. Please check which segment caused it and evaluate usage of Map Matching')\n",
    "\n",
    "    \n",
    "    \n",
    "#         def node_lookup(self):\n",
    "            \n",
    "#         def segment_lookup(self, points):\n",
    "            \n",
    "#         def way_lookup(self):\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading router/new-york-latest.osm.pbf...\n",
      "filtering bbox\n",
      "removing way ids with duplicated node ids pairs\n",
      "number of ways if sharing nodes: 45\n",
      "creating spatial index\n",
      "CPU times: user 5min 11s, sys: 2.18 s, total: 5min 13s\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "PBF_PATH = 'router/new-york-latest.osm.pbf'\n",
    "print(f'loading {PBF_PATH}...')\n",
    "osm_ann = RouteAnnotator(PBF_PATH)\n",
    "\n",
    "print('filtering bbox')\n",
    "b_l = [40.498266, -74.270820]   # NY\n",
    "u_r = [40.915519, -73.680854]\n",
    "# b_l = [63.351348, -24.751708] # Iceland\n",
    "# u_r = [66.615533, -12.362366]\n",
    "bbox = [b_l, u_r]\n",
    "osm_ann.apply_bbox(bbox)\n",
    "\n",
    "print('removing way ids with duplicated node ids pairs')\n",
    "osm_ann.drop_duplicate_way_id_nodes()\n",
    "\n",
    "print('creating spatial index')\n",
    "osm_ann.create_spatial_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt with OSMNx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from itertools import combinations\n",
    "from shapely.geometry import Point, LineString, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "class RouteAnnotator():\n",
    "\n",
    "    # TODO add different forms of network retrieval from OSMNx\n",
    "    def __init__(self, place, network_type):\n",
    "\n",
    "        self.segment_lookup_ = None\n",
    "        self.way_lookup_ = None\n",
    "        self.node_lookup_ = None\n",
    "        self.G = None\n",
    "\n",
    "        # TODO: Need adjustent. See https://wiki.openstreetmap.org/wiki/New_York\n",
    "        self.HIGHWAY_SPEED_LIMITS ={   # copied from https://github.com/Project-OSRM/osrm-backend/blob/master/profiles/car.lua\n",
    "            'motorway':90,\n",
    "            'motorway_link':45,\n",
    "            'trunk':85,\n",
    "            'trunk_link':40,\n",
    "            'primary':65,\n",
    "            'primary_link':30,\n",
    "            'secondary':40, # original: 55 - changed to NY where secondary = 25 mph ~= 40 kmh\n",
    "            'secondary_link':25,\n",
    "            'tertiary':40,\n",
    "            'tertiary_link':20,\n",
    "            'unclassified':25,\n",
    "            'residential':40,\n",
    "            'living_street':10,\n",
    "            'service':15,\n",
    "            'footway': 4,    # custom\n",
    "            'path': 4,       #\n",
    "            'pedestrian': 4, #\n",
    "            'steps': 2,      #\n",
    "            'track': 4,      #\n",
    "            'piste': 4,      #\n",
    "            'corridor': 4,   #\n",
    "            'bridleway': 4,  #\n",
    "            'razed': 4,      #\n",
    "            'elevator': 0.2  #\n",
    "        }\n",
    "\n",
    "        self.G = ox.graph_from_place(place, network_type=network_type, simplify=False) # example - 'new york, usa'\n",
    "        self.add_speeds()\n",
    "        self._build_lookups()\n",
    "\n",
    "    def add_speeds(self):\n",
    "\n",
    "        for u, v, k, data in self.G.edges(data=True, keys=True):\n",
    "            if 'maxspeed' in data and type(data['maxspeed']) == str and data['maxspeed'].isdigit():\n",
    "                continue\n",
    "            else:\n",
    "                if(type(data['highway']) == list): # sometimes data['highway'] comes with a list\n",
    "                    cond = [elem in self.HIGHWAY_SPEED_LIMITS for elem in data['highway']]\n",
    "                    highway_type = data['highway'][np.where(cond)[0][0]]\n",
    "                else:\n",
    "                    highway_type = data['highway']\n",
    "\n",
    "                if(highway_type in self.HIGHWAY_SPEED_LIMITS):\n",
    "                    speed = self.HIGHWAY_SPEED_LIMITS[highway_type]\n",
    "                    data['maxspeed'] = speed\n",
    "\n",
    "    def _build_lookups(self):\n",
    "        # build segment lookup\n",
    "        segment_lookup = {}\n",
    "        segment_lengths = {}\n",
    "        way2nodes = {}\n",
    "        way2nodes_pair = {}\n",
    "        way_lookup = {}\n",
    "        way_segment_lengths = {}\n",
    "        node_lookup = {}\n",
    "\n",
    "        # build segment lookup\n",
    "        for u, v, k, data in ra.G.edges(data=True, keys=True):\n",
    "\n",
    "            if(type(data['osmid']) != list):\n",
    "                way_ids = [data['osmid']]\n",
    "            else:\n",
    "                way_ids = data['osmid']\n",
    "\n",
    "            for way in way_ids:\n",
    "                if(way not in way2nodes.keys()):\n",
    "                    way2nodes[way] = []\n",
    "                    way2nodes_pair[way] = []\n",
    "                    way_lookup[way] = data\n",
    "                    way_segment_lengths[way] = []\n",
    "                way2nodes[way].extend([u,v])                    # add all nodes associated to a way\n",
    "                way2nodes_pair[way].append([u,v])               # add pair of nodes belonging to way id\n",
    "                way_segment_lengths[way].append(data['length']) # collect way lengths to sum up afterwards\n",
    "\n",
    "            if(u not in segment_lengths.keys()):                # store each node-node direct segment length.\n",
    "                segment_lengths[u] = {}                         # NOT DOING ANYTHING WITH IT FOR NOW\n",
    "            segment_lengths[u][v] = data['length']\n",
    "\n",
    "        # 1st FOR, build node id sequence belonging to way_id\n",
    "        # 2nd FOR, sum segments lengths and add node id list to way lookup\n",
    "        final_node_sequence = {}\n",
    "        for way_id, values in way2nodes_pair.items(): # key: way_id, values: pairs of node ids\n",
    "            relations = {}\n",
    "            for pair in values:                       # build dict - key: node_pre - value: node post\n",
    "                relations[pair[0]] = pair[1]\n",
    "            keys = relations.keys()\n",
    "            values_ = relations.values()              # if a key (node_pre) doesn't exist in values\n",
    "            begin_key = list(keys - values_)          # it means it has only origin = way initial node\n",
    "\n",
    "            if(len(values) > 1 and len(begin_key) == 1): # if NOT cyclic sequence?\n",
    "                begin_key = begin_key[0]\n",
    "                node_sequence = [begin_key]\n",
    "                val = relations[begin_key]\n",
    "                try:\n",
    "                    while(val not in node_sequence):  # run through `relations` finding the node sequence pair by pair\n",
    "                        node_sequence.append(val)\n",
    "                        count += 1\n",
    "                        begin_key = val\n",
    "                        val = relations[begin_key]\n",
    "                except Exception as e:                # until a pair is not found in the dict anymore = exception\n",
    "                    e                                 # do nothing in exception\n",
    "                final_node_sequence[way_id] = node_sequence # and store node \"ordered\" list as a Way metadata\n",
    "            else:\n",
    "                final_node_sequence[way_id] = list(keys)[0] + list(values_)[0] # if way has only 1 node, store it as it is\n",
    "\n",
    "        for key, value in way_lookup.items():\n",
    "            way_lookup[key]['length'] = np.sum(way_segment_lengths[key])\n",
    "            way_lookup[key]['node_sequence'] = final_node_sequence[key]\n",
    "\n",
    "        # build dict: key1: node1, key2: node2, value: way_id between ALL pair of nodes id IN way\n",
    "        nodes2way = {}\n",
    "        for key, values in way2nodes.items():\n",
    "            for pair in combinations(values,2):\n",
    "                if(pair[0] not in nodes2way.keys()):\n",
    "                    nodes2way[pair[0]] = {}\n",
    "                nodes2way[pair[0]][pair[1]] = key\n",
    "\n",
    "        # build dict key1: node_id, value: node_metadata\n",
    "        for node in ra.G.nodes(data=True):\n",
    "            node_lookup[node[0]] = node[1]\n",
    "\n",
    "\n",
    "    def segment_lookup(self, node_id_list):\n",
    "        if(type(node_id_list) == int):\n",
    "            return self.segment_lookup_[node_id_list[i]][node_id_list[i+1]]\n",
    "        else:\n",
    "            ways_id = []\n",
    "            i = 0\n",
    "            while i < len(node_id_list) - 1:\n",
    "                ways_id.append(self.segment_lookup_[node_id_list[i]][node_id_list[i+1]])\n",
    "                i += 1\n",
    "            return ways_id\n",
    "\n",
    "    def way_lookup(self, way_id_list):\n",
    "        if(type(way_id_list) == int):\n",
    "            return self.way_lookup_[way_id_list]\n",
    "        else:\n",
    "            ways_lookup = []\n",
    "            for way in way_id_list:\n",
    "                ways_lookup.append(self.way_lookup_[way])\n",
    "            return ways_lookup\n",
    "\n",
    "    def node_lookup(self, node_id_list):\n",
    "        if(type(node_id_list) == int):\n",
    "            return self.node_lookup_[node_id_list]\n",
    "        else:\n",
    "            nodes_lookup = []\n",
    "            for node in node_id_list:\n",
    "                nodes_lookup.append(self.node_lookup_[node])\n",
    "            return nodes_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = RouteAnnotator('new york, usa', 'drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RouteAnnotator.way_lookup of <__main__.RouteAnnotator object at 0x10d5d0f60>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra.way_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
