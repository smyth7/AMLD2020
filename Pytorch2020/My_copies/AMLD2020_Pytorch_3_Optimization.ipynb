{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "AMLD2020 Pytorch 3-Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1c4zthqFmKv",
        "colab_type": "text"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://discuss.pytorch.org/uploads/default/original/2X/3/35226d9fbc661ced1c5d17e374638389178c3176.png\" width=\"400\" style=\"margin: 50px auto; display: block; position: relative; left: -30px;\" />\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqUEbBVwFmKz",
        "colab_type": "text"
      },
      "source": [
        "<!--NAVIGATION-->\n",
        "# < [Autograd](2-Autograd.ipynb) | Optimization | [Modules](4-Modules.ipynb) >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xH6Lx8sFmK1",
        "colab_type": "text"
      },
      "source": [
        "### Optimization\n",
        "\n",
        "In this short notebook, we will see how to use the gradient obtained with Autograd to perform optimization of an objective function.  \n",
        "Then we will also present some off-the-shelf Pytorch optimizers and learning rate schedulers.  \n",
        "As an eye candy, we will finish with some live optimization vizualisations.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "#### 1. [Optimization](#Optimization)  \n",
        "#### 2. [Live Plots](#Live-Plots)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwSvtb2mFmK3",
        "colab_type": "text"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ceysWBKFmK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import torch\n",
        "\n",
        "\n",
        "if 'google.colab' in sys.modules: # Execute if you're using Google Colab\n",
        "    !wget -q https://raw.githubusercontent.com/theevann/amld-pytorch-workshop/master/live_plot.py -O live_plot.py\n",
        "    !pip install -q ipympl\n",
        "\n",
        "%matplotlib ipympl\n",
        "torch.set_printoptions(precision=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "t01UTH9xFmK9",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "X6GEsiTfFmK-",
        "colab_type": "text"
      },
      "source": [
        "## Optimizing \"by hand\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRj_kTKdFmK_",
        "colab_type": "text"
      },
      "source": [
        "We will start with a simple example : minimizing the square function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3fSCi_qFmLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "    return x ** 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxgmiQbMFmLD",
        "colab_type": "text"
      },
      "source": [
        "We will minimize the function $f$ \"by hand\" using the gradient descent algorithm.\n",
        "\n",
        "As a reminder, the update step of the algorithm is:\n",
        "$$x_{t+1} = x_{t} - \\lambda \\nabla_x f (x_t)$$\n",
        "\n",
        "Note:\n",
        "- The gradient information $\\nabla_x f (x)$ will be stored in `x.grad` once we run the `backward` function.\n",
        "- The gradient is accumulated by default, so we need to clear `x.grad` after each iteration.\n",
        "- We need to use `with torch.no_grad():` context for the update step since we want to change `x` in place but don't want autograd to track this change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeDdffaoFmLE",
        "colab_type": "text"
      },
      "source": [
        "#### **Your turn !**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atKsaFdKFmLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "28a85161-5694-49a1-9b49-fdaa8d4ec222"
      },
      "source": [
        "x0 = 8\n",
        "lr = 0.01\n",
        "iterations = 10\n",
        "\n",
        "x = torch.Tensor([x0]).requires_grad_()\n",
        "y = f(x)\n",
        "\n",
        "for i in range(iterations):\n",
        "    \n",
        "    # < YOUR CODE HERE >\n",
        "\n",
        "    y=f(x)\n",
        "\n",
        "    y.backward() # compute gradient\n",
        "    with torch.no_grad():\n",
        "      x -=  lr*x.grad # update: change x in place \n",
        "      \n",
        "    x.grad=None # clear gradient\n",
        "\n",
        "    print(y.data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([64.])\n",
            "tensor([61.466])\n",
            "tensor([59.032])\n",
            "tensor([56.694])\n",
            "tensor([54.449])\n",
            "tensor([52.293])\n",
            "tensor([50.222])\n",
            "tensor([48.233])\n",
            "tensor([46.323])\n",
            "tensor([44.489])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZBOf0-DFmLG",
        "colab_type": "text"
      },
      "source": [
        "#### Why do we use `with torch.no_grad()` ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajr-PaLwFmLH",
        "colab_type": "text"
      },
      "source": [
        "Because `x` \"requires grad\", any operation we apply to `x` is recorded for automatic differentiation. As we don't want to track the update step of the parameters, we need to \"tell\" autograd not to track this change. This is done by using `torch.no_grad()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "ucdmErblFmLI",
        "colab_type": "text"
      },
      "source": [
        "## Optimizing with an optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFbFHrNiFmLI",
        "colab_type": "text"
      },
      "source": [
        "### Different optimizers\n",
        "PyTorch provides most common optimization algorithms encapsulated into \"optimizer classes\".  \n",
        "An optimizer is an object that automatically loops through all the numerous parameters of your model and performs the (potentially complex) update step for you.\n",
        "\n",
        "You first need to import `torch.optim`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyLJfuX_FmLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylgwzfuVFmLL",
        "colab_type": "text"
      },
      "source": [
        "Below are the most commonly used optimizers. Each of them has its specific parameters that you can check on the [Pytorch Doc](https://pytorch.org/docs/master/optim.html#algorithms)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9yW2zDMFmLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = [x]  # This should be the list of model parameters\n",
        "\n",
        "optimizer = optim.SGD(parameters, lr=0.01, momentum=0.9)\n",
        "optimizer = optim.Adam(parameters, lr=0.01)\n",
        "optimizer = optim.Adadelta(parameters, lr=0.01)\n",
        "optimizer = optim.Adagrad(parameters, lr=0.01)\n",
        "optimizer = optim.RMSprop(parameters, lr=0.01)\n",
        "optimizer = optim.LBFGS(parameters, lr=0.01)\n",
        "\n",
        "# and there is more ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlCdy2kFmLN",
        "colab_type": "text"
      },
      "source": [
        "### Using an optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po8MOVOCFmLN",
        "colab_type": "text"
      },
      "source": [
        "Now, let's use an optimizer to do the optimization !\n",
        "\n",
        "You will need 2 new functions:\n",
        "- `optimizer.zero_grad()` : This function sets the gradient of the parameters (`x` here) to 0 (otherwise it will get accumulated)\n",
        "- `optimizer.step()` :  This function applies an update step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQjJK6IAFmLO",
        "colab_type": "text"
      },
      "source": [
        "#### **Your turn !**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bODtw39NFmLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "26d5e30b-13bc-48f6-900f-3e8b9eeecd35"
      },
      "source": [
        "x0 = 8\n",
        "lr = 0.1\n",
        "iterations = 10\n",
        "\n",
        "x = torch.Tensor([x0]).requires_grad_()\n",
        "y = f(x)\n",
        "\n",
        "# Define your optimizer\n",
        "optimizer = optim.Adam([x], lr=lr)\n",
        "\n",
        "for i in range(iterations):\n",
        "    \n",
        "    y = f(x)\n",
        "    y.backward() # compute gradient\n",
        "    optimizer.step() # does everything - knows the function x\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    print(y.data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([64.])\n",
            "tensor([62.410])\n",
            "tensor([60.841])\n",
            "tensor([59.292])\n",
            "tensor([57.765])\n",
            "tensor([56.259])\n",
            "tensor([54.775])\n",
            "tensor([53.313])\n",
            "tensor([51.873])\n",
            "tensor([50.457])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGv6lNXGFmLQ",
        "colab_type": "text"
      },
      "source": [
        "### Using a learning rate scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3UwS_Y6FmLQ",
        "colab_type": "text"
      },
      "source": [
        "In addition to an optimizer, a learning rate scheduler can be used to adjust the learning rate during training by reducing it according to a pre-defined schedule.  \n",
        "Below are some of the schedulers available in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVlynXeOFmLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim.lr_scheduler.LambdaLR\n",
        "optim.lr_scheduler.ExponentialLR\n",
        "optim.lr_scheduler.MultiStepLR\n",
        "optim.lr_scheduler.StepLR\n",
        "\n",
        "# and some more ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtla_AuwFmLS",
        "colab_type": "text"
      },
      "source": [
        "Let's try `optim.lr_scheduler.ExponentialLR`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxVx08EvFmLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "    return x.abs() * 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppsb7rAQFmLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5aeca550-466c-408d-be2e-a39e4fdd6833"
      },
      "source": [
        "x0 = 8\n",
        "lr = 0.5\n",
        "iterations = 150\n",
        "\n",
        "x = torch.Tensor([x0]).requires_grad_()\n",
        "optimizer = optim.SGD([x], lr=lr)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.8)\n",
        "\n",
        "for i in range(iterations):\n",
        "    optimizer.zero_grad()\n",
        "    y = f(x)\n",
        "    y.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    print(y.data, \" | lr : \", optimizer.param_groups[0]['lr'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([40.])  | lr :  0.4\n",
            "tensor([27.500])  | lr :  0.32000000000000006\n",
            "tensor([17.500])  | lr :  0.25600000000000006\n",
            "tensor([9.500])  | lr :  0.20480000000000004\n",
            "tensor([3.100])  | lr :  0.16384000000000004\n",
            "tensor([2.020])  | lr :  0.13107200000000005\n",
            "tensor([2.076])  | lr :  0.10485760000000004\n",
            "tensor([1.201])  | lr :  0.08388608000000004\n",
            "tensor([1.421])  | lr :  0.06710886400000003\n",
            "tensor([0.677])  | lr :  0.05368709120000003\n",
            "tensor([1.001])  | lr :  0.042949672960000025\n",
            "tensor([0.341])  | lr :  0.03435973836800002\n",
            "tensor([0.733])  | lr :  0.027487790694400018\n",
            "tensor([0.126])  | lr :  0.021990232555520017\n",
            "tensor([0.561])  | lr :  0.017592186044416015\n",
            "tensor([0.011])  | lr :  0.014073748835532812\n",
            "tensor([0.429])  | lr :  0.011258999068426251\n",
            "tensor([0.077])  | lr :  0.009007199254741001\n",
            "tensor([0.205])  | lr :  0.007205759403792801\n",
            "tensor([0.020])  | lr :  0.0057646075230342415\n",
            "tensor([0.160])  | lr :  0.0046116860184273935\n",
            "tensor([0.016])  | lr :  0.003689348814741915\n",
            "tensor([0.100])  | lr :  0.002951479051793532\n",
            "tensor([0.007])  | lr :  0.002361183241434826\n",
            "tensor([0.066])  | lr :  0.0018889465931478608\n",
            "tensor([0.007])  | lr :  0.0015111572745182887\n",
            "tensor([0.040])  | lr :  0.001208925819614631\n",
            "tensor([0.002])  | lr :  0.0009671406556917048\n",
            "tensor([0.028])  | lr :  0.0007737125245533639\n",
            "tensor([0.004])  | lr :  0.0006189700196426912\n",
            "tensor([0.015])  | lr :  0.0004951760157141529\n",
            "tensor([1.280e-05])  | lr :  0.0003961408125713224\n",
            "tensor([0.012])  | lr :  0.0003169126500570579\n",
            "tensor([0.002])  | lr :  0.00025353012004564635\n",
            "tensor([0.005])  | lr :  0.00020282409603651709\n",
            "tensor([0.001])  | lr :  0.00016225927682921368\n",
            "tensor([0.004])  | lr :  0.00012980742146337097\n",
            "tensor([0.000])  | lr :  0.00010384593717069677\n",
            "tensor([0.003])  | lr :  8.307674973655743e-05\n",
            "tensor([0.001])  | lr :  6.646139978924594e-05\n",
            "tensor([0.002])  | lr :  5.316911983139676e-05\n",
            "tensor([9.805e-05])  | lr :  4.2535295865117404e-05\n",
            "tensor([0.001])  | lr :  3.402823669209393e-05\n",
            "tensor([0.000])  | lr :  2.7222589353675144e-05\n",
            "tensor([0.001])  | lr :  2.1778071482940116e-05\n",
            "tensor([2.342e-06])  | lr :  1.7422457186352094e-05\n",
            "tensor([0.001])  | lr :  1.3937965749081676e-05\n",
            "tensor([0.000])  | lr :  1.1150372599265342e-05\n",
            "tensor([0.000])  | lr :  8.920298079412274e-06\n",
            "tensor([3.686e-05])  | lr :  7.136238463529819e-06\n",
            "tensor([0.000])  | lr :  5.708990770823856e-06\n",
            "tensor([7.743e-06])  | lr :  4.567192616659085e-06\n",
            "tensor([0.000])  | lr :  3.653754093327268e-06\n",
            "tensor([2.080e-05])  | lr :  2.9230032746618144e-06\n",
            "tensor([7.054e-05])  | lr :  2.338402619729452e-06\n",
            "tensor([2.534e-06])  | lr :  1.8707220957835615e-06\n",
            "tensor([5.593e-05])  | lr :  1.4965776766268494e-06\n",
            "tensor([9.158e-06])  | lr :  1.1972621413014795e-06\n",
            "tensor([2.826e-05])  | lr :  9.578097130411837e-07\n",
            "tensor([1.675e-06])  | lr :  7.66247770432947e-07\n",
            "tensor([2.227e-05])  | lr :  6.129982163463576e-07\n",
            "tensor([3.114e-06])  | lr :  4.903985730770861e-07\n",
            "tensor([1.221e-05])  | lr :  3.923188584616689e-07\n",
            "tensor([4.858e-08])  | lr :  3.1385508676933514e-07\n",
            "tensor([9.759e-06])  | lr :  2.510840694154681e-07\n",
            "tensor([1.913e-06])  | lr :  2.0086725553237452e-07\n",
            "tensor([4.364e-06])  | lr :  1.6069380442589963e-07\n",
            "tensor([6.576e-07])  | lr :  1.285550435407197e-07\n",
            "tensor([3.360e-06])  | lr :  1.0284403483257577e-07\n",
            "tensor([1.459e-07])  | lr :  8.227522786606062e-08\n",
            "tensor([2.425e-06])  | lr :  6.58201822928485e-08\n",
            "tensor([3.683e-07])  | lr :  5.26561458342788e-08\n",
            "tensor([1.277e-06])  | lr :  4.2124916667423047e-08\n",
            "tensor([3.924e-08])  | lr :  3.369993333393844e-08\n",
            "tensor([1.014e-06])  | lr :  2.695994666715075e-08\n",
            "tensor([1.714e-07])  | lr :  2.1567957333720603e-08\n",
            "tensor([5.026e-07])  | lr :  1.7254365866976484e-08\n",
            "tensor([3.658e-08])  | lr :  1.3803492693581187e-08\n",
            "tensor([3.948e-07])  | lr :  1.104279415486495e-08\n",
            "tensor([4.969e-08])  | lr :  8.834235323891961e-09\n",
            "tensor([2.264e-07])  | lr :  7.067388259113569e-09\n",
            "tensor([5.526e-09])  | lr :  5.653910607290855e-09\n",
            "tensor([1.712e-07])  | lr :  4.523128485832685e-09\n",
            "tensor([2.981e-08])  | lr :  3.6185027886661478e-09\n",
            "tensor([8.327e-08])  | lr :  2.8948022309329185e-09\n",
            "tensor([7.195e-09])  | lr :  2.315841784746335e-09\n",
            "tensor([6.517e-08])  | lr :  1.852673427797068e-09\n",
            "tensor([7.279e-09])  | lr :  1.4821387422376544e-09\n",
            "tensor([3.904e-08])  | lr :  1.1857109937901237e-09\n",
            "tensor([1.984e-09])  | lr :  9.48568795032099e-10\n",
            "tensor([2.766e-08])  | lr :  7.588550360256793e-10\n",
            "tensor([3.944e-09])  | lr :  6.070840288205434e-10\n",
            "tensor([1.503e-08])  | lr :  4.856672230564348e-10\n",
            "tensor([1.498e-10])  | lr :  3.8853377844514787e-10\n",
            "tensor([1.199e-08])  | lr :  3.108270227561183e-10\n",
            "tensor([2.279e-09])  | lr :  2.4866161820489464e-10\n",
            "tensor([5.492e-09])  | lr :  1.9892929456391572e-10\n",
            "tensor([7.244e-10])  | lr :  1.591434356511326e-10\n",
            "tensor([4.249e-09])  | lr :  1.2731474852090608e-10\n",
            "tensor([2.703e-10])  | lr :  1.0185179881672488e-10\n",
            "tensor([2.913e-09])  | lr :  8.14814390533799e-11\n",
            "tensor([3.663e-10])  | lr :  6.518515124270393e-11\n",
            "tensor([1.671e-09])  | lr :  5.214812099416314e-11\n",
            "tensor([4.110e-11])  | lr :  4.171849679533052e-11\n",
            "tensor([1.263e-09])  | lr :  3.337479743626441e-11\n",
            "tensor([2.196e-10])  | lr :  2.6699837949011533e-11\n",
            "tensor([6.147e-10])  | lr :  2.1359870359209227e-11\n",
            "tensor([5.277e-11])  | lr :  1.708789628736738e-11\n",
            "tensor([4.812e-10])  | lr :  1.3670317029893907e-11\n",
            "tensor([5.403e-11])  | lr :  1.0936253623915126e-11\n",
            "tensor([2.877e-10])  | lr :  8.749002899132102e-12\n",
            "tensor([1.432e-11])  | lr :  6.9992023193056814e-12\n",
            "tensor([2.044e-10])  | lr :  5.599361855444546e-12\n",
            "tensor([2.943e-11])  | lr :  4.479489484355637e-12\n",
            "tensor([1.106e-10])  | lr :  3.5835915874845095e-12\n",
            "tensor([1.431e-12])  | lr :  2.866873269987608e-12\n",
            "tensor([8.816e-11])  | lr :  2.2934986159900865e-12\n",
            "tensor([1.649e-11])  | lr :  1.8347988927920693e-12\n",
            "tensor([4.085e-11])  | lr :  1.4678391142336555e-12\n",
            "tensor([5.020e-12])  | lr :  1.1742712913869245e-12\n",
            "tensor([3.168e-11])  | lr :  9.394170331095395e-13\n",
            "tensor([2.319e-12])  | lr :  7.515336264876317e-13\n",
            "tensor([2.117e-11])  | lr :  6.012269011901054e-13\n",
            "tensor([2.378e-12])  | lr :  4.809815209520843e-13\n",
            "tensor([1.265e-11])  | lr :  3.847852167616675e-13\n",
            "tensor([6.283e-13])  | lr :  3.07828173409334e-13\n",
            "tensor([8.991e-12])  | lr :  2.462625387274672e-13\n",
            "tensor([1.296e-12])  | lr :  1.970100309819738e-13\n",
            "tensor([4.861e-12])  | lr :  1.5760802478557904e-13\n",
            "tensor([6.431e-14])  | lr :  1.2608641982846325e-13\n",
            "tensor([3.876e-12])  | lr :  1.008691358627706e-13\n",
            "tensor([7.237e-13])  | lr :  8.069530869021649e-14\n",
            "tensor([1.798e-12])  | lr :  6.455624695217319e-14\n",
            "tensor([2.194e-13])  | lr :  5.164499756173856e-14\n",
            "tensor([1.395e-12])  | lr :  4.131599804939085e-14\n",
            "tensor([1.034e-13])  | lr :  3.305279843951268e-14\n",
            "tensor([9.295e-13])  | lr :  2.6442238751610145e-14\n",
            "tensor([1.032e-13])  | lr :  2.1153791001288118e-14\n",
            "tensor([5.579e-13])  | lr :  1.6923032801030494e-14\n",
            "tensor([2.903e-14])  | lr :  1.3538426240824397e-14\n",
            "tensor([3.940e-13])  | lr :  1.0830740992659517e-14\n",
            "tensor([5.558e-14])  | lr :  8.664592794127615e-15\n",
            "tensor([2.152e-13])  | lr :  6.931674235302092e-15\n",
            "tensor([1.429e-15])  | lr :  5.5453393882416744e-15\n",
            "tensor([1.719e-13])  | lr :  4.43627151059334e-15\n",
            "tensor([3.323e-14])  | lr :  3.549017208474672e-15\n",
            "tensor([7.768e-14])  | lr :  2.8392137667797376e-15\n",
            "tensor([1.105e-14])  | lr :  2.2713710134237903e-15\n",
            "tensor([5.993e-14])  | lr :  1.817096810739032e-15\n",
            "tensor([3.148e-15])  | lr :  1.4536774485912258e-15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "id": "WDZiq1y-FmLV",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Live Plots "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqPswx_WFmLW",
        "colab_type": "text"
      },
      "source": [
        "Below are some live plots to see what actually happens when you optimize a function.  \n",
        "You can play with learning rates, optimizers and also define new functions to optimize !\n",
        "\n",
        "_Note: These are not stricly speaking live plots as it is not possible to do so in colab. We actually create a video of the optimization process instead_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHtjGmHwFmLW",
        "colab_type": "text"
      },
      "source": [
        "## 2D Plot - Optimization process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD-iux6JFmLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from live_plot import anim_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxWIuYE9FmLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def function_2d(x):\n",
        "    return x ** 2 / 20 + x.sin().tanh()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8pAkG2bFmLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "be8fb49a-7db5-4b29-d5c2-5d6ed678e29d"
      },
      "source": [
        "x0 = 8\n",
        "lr = 2\n",
        "iterations = 15\n",
        "points= []\n",
        "\n",
        "x_range = torch.arange(-10, 10, 0.1)\n",
        "x = torch.Tensor([x0]).requires_grad_()\n",
        "optimizer = torch.optim.Adam([x], lr=lr)\n",
        "\n",
        "for i in range(iterations):\n",
        "    optimizer.zero_grad()\n",
        "    f = function_2d(x)\n",
        "    f.backward()\n",
        "    points += [(x.item(), f.item())]\n",
        "    optimizer.step()\n",
        "    \n",
        "anim_2d(x_range, function_2d, points, 400)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video width=\"432\" height=\"288\" controls autoplay>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAlQG1kYXQAAAKtBgX//6ncRem9\n",
              "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
              "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
              "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
              "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
              "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
              "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MyBsb29r\n",
              "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
              "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
              "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
              "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MiBzY2VuZWN1dD00MCBpbnRyYV9yZWZyZXNo\n",
              "PTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0wLjYwIHFw\n",
              "bWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAAGfJliIQA\n",
              "Fv/+99M/zLLr9zm146j3op4mX0N1JQGblsTtOoAAAAMABnblzZfZ7UFwH2gAB5VRx2B/T/5gCHXE\n",
              "zSRFjyzhEMbsFROFOzvcJ3+SfvbucJqMU+gJsQkFL9vJGZpowLbmJLxKj9Q5sHPXoBB6xyNAVjlt\n",
              "Pg0PcCd4NWkmfJT5C8igTMSPorCzUWBUsXmqEFhQw/FqO+qZRL3bSbgtp6qfhKZbdMivRLoACEKi\n",
              "EYxzmtDl/8VCreKoawEP7/iDUw2AkhKFN/N6ZavmCt6JZ3A7gvDILvFHC41Pasr+5GPE45FvkNwp\n",
              "X6/dK6GFVukalMMOrjUS/RqtLbzuay1CiH/j9OzEEeP50NogOuMNijfKsmhwkj3nSokfynxS98jD\n",
              "tZyi5wZ5Z0/7c5Pu3q1hiHSzqUjBOmdSEZouhwAu2w4ZlT9dltJQewtrhiaLcTqMKcYCRJd44sY6\n",
              "JAvwcBc1j9LmPek5QAAAfs0w/+uRb1rA+HZ8NW6YQQpQowlaR2Y/pS6fKfKityaLYvhqTe8Ouc7c\n",
              "maJJT3sCLAOpI4JljK38A1QNI7Iz9GAUvscF4n4ATcHQ82eysZnVbzwixql7t/PegQXqwTFhWjXM\n",
              "m9dEiJQqQ2BJRoP6RRrEa8/gCSEgWvK2TyLDCHsUZl7/yWGIJ5O4pTzzjsxY2tpnl0w73MjQ7VGL\n",
              "ipEgXaXMhknf12V/wBlVAgi1zw5oc7zmtsJd7fg4yWakhhcFXFNr3FwGC0fzsHISNPphEQtYzC33\n",
              "DMQneZeg/mXHh3sDxt3EgzoGKGiNq3AmKtwaFM9+r3mN5luTprFBuPgt+dVj7n6I+0jTIDyreajv\n",
              "tghQ+95Oxhf21va5e4ltLCBz+kutbucDD7fIx4246xNY46ngYIvbMvvgixLIhFNE0SdBFKTSlom1\n",
              "gAv5DuMelcl7mZR8P196PXuZ3OdCLgT4is8pDy9sCOb6DZEmpu5JOoh4uA1TB7v69qtOD9VAIYVt\n",
              "purArdKNiy/xRbT8TvvW6gGQ+4DdWPWxDkEWBavTYKphoWscxOJdKXV5AoP6BLnwNA71xu3GAHhB\n",
              "Q+XR+Xe3tbqf4d7w/bOIYXKz5hTJP14RLutmGbpknLD9dXRmBg6vlWp6CepFpHC4pUQLQ538UK+f\n",
              "jbT4W3iZvHcGtK3hpQKSBshawiyBo9mEoLHVLXARfaoWliYrh0z/68FiD4BphUse+ZgeU/a0Bvvk\n",
              "4RpTjouQcvsV7BfCEdnDZRm+HNbsjVxpw41tpTdO+0A7uuzTlhLHLCR9TRkBr//pucGF//5cetP8\n",
              "16LG7vzidXHbTSboMNxBwVS5F4vA+//tyLRAy/l0l/b19bvF+c4IaqJfGvZ+hcRvmwA4WjFHn1Kh\n",
              "gHL0gbkG2blaMn6sYuSFDK/feiv5OrmRvXZAJnTOB1TPKf5OpC4gDIG4mnlSkxnSFjXQ8NnR561B\n",
              "k5hNdxpy/Jj3HAEcDsFZO9atQhNP4bUeGFB5AsCN3pBtCCExQVeSrYyBOZ3jxAIYCBNPv7raBa64\n",
              "UayymgSI595fV/Z5dI7rF2YQu+cbgcZy8JkwL1BrV5I1m/f5+qLVwmdJ6K9FHOpSGCyagSND3kXh\n",
              "6kP7owElwMHf/Ky+VmeY+nb1JYidTdAIS0UWi93j+hxAdkRf5kjSkiBo71LgbN8SY0V54Ee8ThST\n",
              "VFnp6eG88KINisreK2/iYmohDV5zDEiUstpnsozTlVIODwMvYpQMtJvdIDMv4dPNgAq6t06Z+Jhu\n",
              "kiJUf1Gl42lhorJlm1+mpii23SBQVdq3Px0qAV8Tj03zmC17xBfKukyeqRW5Q3FSd5umNBsyyF48\n",
              "ata06ClLEnvoS+Jo2u3J1XupoDuLNsy3/grFqZiCzDc4AbYin/DTY4umTtBREf9qXUYyBuaHM2ek\n",
              "wq0pIou7vl9oOPyKbguiypZK1ElLkFORrpgYxiP5DLS+KlYA1OQwnGW+Mwf/feO9G77Snc+6KOdJ\n",
              "NecVid3B9criJYkNMHFS8Z5mghhjd7QBnAvVGJQkF5qzstEJSpEwWn9P51DES7bG1ql5YG0C1hOm\n",
              "jSyr2lW94HR4uinQa+0MVijnEPSDTaj5EvKvVrsxZpOCcqh6MIIlytuu9XAuXfsZ6pqEZcEb6DfS\n",
              "1DiBikka0CDmYCbyGEGWkLKwJ9ElqFp+f4LxjkGVrgCJifmwftZk339j5K8gkXipd1bwJlk1CmUX\n",
              "NNJ4pbrKO4wGD0l6cX7ngfOzWsDBh0t1SdkA7hdSccnU1bEr8RDMGlKDKVR+9Rdkohs7oUuQcgbh\n",
              "kzZXLXRZsU95kZTViR2PWgJ1KXjtLSAeGpMmPOeMQmCt4fljGZu1Mkq8z/EbhWrUriTjftjP1N4I\n",
              "kvl0TIm42ruQogW2oFb6LuB+bvI38WKQfu86I3kCZn70US/vTg0irVUeA5fqGStjXX6V2CErjc9f\n",
              "WJIpBeRE7hVis5YnCCqfAO/SUORn6o+Vinehe6zSQAfuvrka3V7FdsvN3oc6/F2nkkZMLezswLy6\n",
              "Li56GcKSylFv/tD1oOWf1bG9qxuKUERE9jgrwlrhUfbrw0gkWc218shOvvj37r5HHQRdPQQvSAZk\n",
              "vz/1nZ5FuhWfAOt+R4dXKAVaoT0Qai3UK6mtIV4Lch+WfyBXHEoDZFOvvvi2Pd7kHZMK/x2JOQFz\n",
              "fLmyH4FarDhcVOAMQm1LEkjIaTAhlIqXSdEBV6L/oJP/q9qAH0tGHkg4PiffeGZczkVc6h8/oS9D\n",
              "4K57hc82mOK9bJ60piDWnn0LvFEb3h2Mng3gftlkq7VPaesHCTCVfFUCOgjbEotip5pVLlt0MLdF\n",
              "vzbYEqr4tPEZ/Olz9iuVxQtRi8GaDdgyby/9HORCyOAv4GaVuh71+MQFvzLBi5bmzhPtONEcrg0R\n",
              "jWwb4TPa4NQi6U7VG1VcelUJAzUCALq9tlP87p8pVAcqAu5vfr63RgBkCjb0KH+f1qenMts09exj\n",
              "nFdprvnyGhpnaDAaaLp0L+2Etf22iXxOrqr0qj1f0t1y3xSXUsfZhQuw1hwMSmXDLt9mZfk/WB8A\n",
              "Kh7eahfbd2pWBZW1W3NzP9ZipKVt+SoHmilIW01rnPrgaHpiCzg04RVyzNpdNUb4KJ4FEPcXWvXv\n",
              "vJFAVWRn1Iplmr1HM1hlwt4C1RifektoPottVO+BJA+lOR9gtSRGSVGgPmxGa4fTTZgEYVObGJqM\n",
              "UsIqihMW4zgQygAPgFnIQP8Zyox6lAHwZvkXSOeoxwvT8cJrHiwzo4jfAC5aALjXGpmnX0mBtD32\n",
              "D111+ChUW3J8ZLchXrFL02S/YwwqHDBSU6rldwPj+aIsMfO2vZcNDWjkjOhD9OQwNrzwXvNtiRdL\n",
              "wOI+Scy1x3MInT8+bov56At3NXOg6QHS+xdzIig+JdupG3w1P8/YLUe3NbZVB8q6SGbQaY7ZMJzm\n",
              "WA6IESKwFdToWU7fvCUTC3t0EASvjSEf2rHs34ssMIAMdJsLlUDvYOhpoJ17wG+nVhxdDrIOz+uM\n",
              "rqwVnK74E9khYRGKf6degc6va9OXYOfoFp0n0KPoo0cjsgruHGo0IP01unzLIx6sOYg6YLO7AMEF\n",
              "oF0b7rqG1D9SAToO5PCwEwlrbAn4VEgLXTqBErlLGoWnjosuGefvzyw1oBoCvRO8mrWJTHHEjBw/\n",
              "Axyq1vyvB0+agdUWNKqvEFQb1HULn8Zji6+FCr66ElC0oqBkgP7XHGNle07sP/wvSqcMKA8JSW6w\n",
              "BFMl9NQRTNla2KXmihVTU1yxNVJd8uerQuDtpjBOjbkx3+qmmuHalTSoMLNxZQsdxoAbCqJKFuoi\n",
              "Jx3fxpyYhcKnIMkNE5+Jj16qLmljd2qoZkZ6SdL5R1fG9VW3rTdp4M0qhuftU/Qv1gbP1cGMlONC\n",
              "d//83/5ur7DHJ6Ofc9lfOZiiH+2GDGQPrHJTnFpBEY6jHveDM4zGF/lFyKnfaIPwp/BiAt55kr8/\n",
              "0cDFRq48QxCDhYY0ZSWRu2xdhocY9qW1/PxBTQu4sGfKeWWqX8ctgurnbWAP+wskqgoum5RVbYBc\n",
              "HyZRYec/bWJKbUnYXo1RhdNsHqVt71zGTAJJlnIrmLCqgS3jixYLYDtyxP//R5ecYIOCK3FlbILD\n",
              "Nx9lZptfLlDE4n8IJw62Ttr5k0wm8LTbN4/QK8MViRzlBW7y7IWaSZyghFuo1eXBMtusY7x5dS6Y\n",
              "sbyjH4KUN/ChZvNyMHzw3hPSfGUmUWIrmMcqU/UaBZ4liy35suuUesGl4fAfVuVacsYm0dzHffzX\n",
              "lydQMkV6r0YdY+twRhTsPyc7rONP42nOSRqZD9TDR4JDW6W55K5r0GMZE1UUsBr8cgwbgktEEhbA\n",
              "YVyWleckeb5T8TXJuT7BvpfPd2JANjLts1214CGcc9zNDHD1MLF0J4pnmrxz5+6ogXHFJ6zFzKW0\n",
              "RbeL58inNHIdhVpNx7wSwB6m2mzHbLijOk7AEGRZ8Frj9u0o9SP5eVnrTJAPDsuvmkiQ2v6ZbN+w\n",
              "jjWEn55EPk5Fzncsu1PMNSkAxXZ4TXA/daD5+JCnr+a4cv5fpFmyTgyQrPKs5azgS0S0iVbcyGjR\n",
              "bCr4UABcz/CKB7W1/wvzgcpX3a3iNcvqad73rpHhtj+pZ1cGgozdH9vvxisnrwcC0ROPAWP7fHUj\n",
              "th+nCgckxjBvGiHDXFlgqO9T4LIQdFEDKHToykM/jqCy//2FoM+fjXtLv/1UjTXFsL5HiWnvgYJr\n",
              "qnuicjyHcIxyOhsIy7wBmGzAKLJFMN8kM4AzNlLer511o8WCoAZVgzPfIwabONvvDELAa1P2FvkB\n",
              "zv4x5pc/eyXGuVm/vHrNtcAad3zgo+PxO1BiTUnj+5/sl1D1ntmUUIWkz3kDIfTp3y7B8h3O0WMy\n",
              "dlwPfMOeQpDj4Oza/vvl43y3LoX6FJT219GrNqNJfgGI9Uz9IvUZKBMwfUFOU66EiUCFK5cprrT8\n",
              "qWoK0U6xf8l0ezr4l07VmRTJXr/HcyJ/uc91GKMEbePj9l3aaA9C5hcVDLkK1LQ/OlzTJSSLs+gy\n",
              "lMAZo+iwFWn2HJISghIEISqJT0hrYhjDYMgLJvbZJqFbvZnsRTZALeS2Yz9jxZH2kbsEfKyO6MRr\n",
              "LDZuGgrm5OVAyhhSGqSMWbvIY8SjOgq7Tf3oenfjqjG08Erlx16dfgvAsJZyq/b9lQGgSh0Uc1uf\n",
              "LRGw35oGN/9QC1U/JoVv1E99Ie3YCMFW91DJTFQrtTCNQBM9VqwRCZ2km4JRDsCiv8ocjsNcx5DA\n",
              "gWv1Cp0gFu41WLidjzc514IRotCbha4OqjFpIKw+yTTa+4tkHVEksb9mbpRxNMmMdrkzzGmzEbvm\n",
              "cVZhnXNBcnn+YQH73E9gJJun2AEtLcUqImx1z3AoWC+LVVOCG1G/d0GoDtz6QOEHgAstx4QrDlpL\n",
              "2kb6WlyLESlki792qI5FzBSegryv2qQiqbblAWVObsWHH+qorgWwiUes2qyjEBv/P3dqf8lBI7uk\n",
              "ibDDcfGL5ZJwSv+8kxCE3Zv95pLXcQz9YvQwQ/aUCvIps2N+TtZEaci5fT3QuifZjKp54ex/G98o\n",
              "zdCEwI9aqosJatT55oiqyar1LIjCVOZcyZwZc6/1lB84vCamzxbdcfjHAxmYHLf/bJ4jcrMOhsiw\n",
              "Xtl3wI7Kh0ptzFGCZJsUDuomkpaZOa/AYH7j1cjuUNFjnNGKS47+fD8dWwtCxy8kYAjhUHa8+s7d\n",
              "NyBafqiOjhd2f33GHrlNc01axdTCVsGRG08fGKzVoYgnbcj9fXzWf+3mQFlHhhtwfM+LIaLdd0PB\n",
              "tkSANfTJJ8aX4hFLPBgHGcOOVXIsbNp7ryvgw3Ctf/UlS7y70850FARrUCktowjqAYHHF0nIxfKh\n",
              "ZgBRYk/W55V928u4yPBOZIqs0w6Tyl+ea3Ue9n8KanSbx6CeTi4P0pzgn1LscCT6EkhfhPT/fJLb\n",
              "kGOK2h+fGjctTtQv/rqKoKDuaXwkwpK7X6GCRZEAON8RzWXQKNW2qJJjBjRwV5WIVejPI485ttkP\n",
              "0JygDvvGcnWSGHXl1PPKbxYNojfBfKw84yD5FtP4BGrbI3HEoG0ou/lT40CzheovC7qySJQMkGyv\n",
              "pisrzEPmh6jzwFkR/JyhZQwT2UZzZO5k7k1/mM81pHlEIDyN1jokzOyGomJbYLexFl46ut9fCn15\n",
              "jZHa7MnqcEF85oGU3QEmRxGv+aT+8aHB+axc8rq770quZn/K+rMbUYqlsN/u/s8cQ9AwHF26IdeO\n",
              "BzL/yfEUQj78LCwDIaECpTbLwclB/X53DFwNR2pe64/+Xx/7NMIhRJh/I1YBg+CUWmCS43PYQQBp\n",
              "LxOV7TnXjz/eO55d6It4BsRsQV6PHOU1trA2P3bzcOINW88J/7GEI8D+kShsQ4NAa2C5XtWyj11Y\n",
              "utwG9YQjxVMZgMaBdYqPJQqlXb/Ij5TjUnvM2ULI8oMjMDfhDMOhhw1EsWWfHrYt4+ggfOVcaL/7\n",
              "x107OSt/p4sYwtahLdLyEOptrf5PazPZSFauzJdrz7FSPGDSuCbMS5ON76iHCegncw7e+6b/f/Sy\n",
              "vb5EvzCaE+s7rRce6qu+YnBEU7ylF3S09w2D3jY3v9hWI+6/gj6hc2QTR/Z8667XfeAWZRIGoWbU\n",
              "esaKUMR8orHh3/NHGFR14k7xpDQf8fqp5s6vDqZdZAN+1p4wrSLHoGEc2z75HjqANMymzI/mw5Bn\n",
              "iDS3MfPtW362E8SFhubRhkvixa46NkDyXC7u/QCYggaTzqQ508zYdlERe2hO8EuPgUqQFvX7dBD9\n",
              "ONq8+H/Z4GMX0mUw3Y1bnFcAWJnrDagjwh0tp7+NmJJcRChehuTlxQCuxG1cVgsuByhOXJnJNQnz\n",
              "lAIHezuPzT09EFZ3ewQLvQASFKOTZIfyzRBwe9LFED/m6R07fPsdRBqISWUvvWjOTCwvKrFP9+WD\n",
              "B/hWQhcUS0iIMNE3dlOKIsoNcEuV3QLVNePKHDfzRN6ROsufXqo0FghtwhqBZjMyN3UsvW7omore\n",
              "okEw3qJHH7ILs+CzZ55bRQ6EKyKQkWfyLzuVcVDXYsCcDYIkbOMyZxvgAnqhIbd3nQ4sk1df5CP4\n",
              "yXIlrF2prl/gRpoAKdCXIDnAnI2YAsGfFM03j/OBY+/FNK8l2oKW49XwrjVbTkTOE73sJBsrfACb\n",
              "xHkmRiauCsVf7VICbp9NP8a3svXv77+SObz/YmaN/WTeoL0jI9U3C8xXm5zxRImV8MlnNOA4muvI\n",
              "B7+htqMP8nh6U0dJxYdOx4JIMNGLNJgISY9dyNJ36gJ18CVxOpD3eIbksOobXHvKKlV29oJfSgty\n",
              "yM//4omrO8Ou+fNUrlZGKvoLAzALSpCv/Z8c0SYDx7ZTbCv3zTJn2/FzgLobDtbEqVs5yCGgB/4M\n",
              "5Hv0jaAqi8sSGjPcTfNZXKcBfi+9RGIu5r1SSiu4xK4kw0jNLZ0lU3w48RIZirW720/XluXUpGRp\n",
              "90Alhjl8IY7xOxm3O7LL+yLsMPM7PxFTu4G6WXKoryHDxKqH9n7EzueN+WTwyNyk4+x456JUKDmA\n",
              "Mb1xqrnH+S6hcD+BTNTYTqPgUvpM4Yu0ZzrdbjNo09wL8s8bTc9buehnsc3yXmjDTb9+EwyONam8\n",
              "HFSSq/sACpkWbJu5w1fd3arPIG3gJAiuOmGTt507uugkSXEzLbRxGTrHc6vCjb7N112IneEk1VGj\n",
              "4EPncSgSV1MzeDaQi9vTmiOAgJZp4iy7vTcmbA7J3x7ns3BKFdWauN4kHUm+KL+vugGQ4ZJfVwvq\n",
              "fBpgWNwVZsVDIl4d5ORheMhSoJ+Gi1PHJzZ76PynUSLmQeYqz+RYjY3OtirdS00ZOYpQIAl8UuQQ\n",
              "rFEeErQ6Mvv+j/eNNuQcKFfkSFXaqT9/udfbG9YDiBFVrB841Yt1MBOs3d9Th3X4/xFFPmbroHRX\n",
              "Uge/owyXM8T9a9ecOC/EnfDK61VYmJlsbvEjnNftp+H8qFkO6GFjmLiY7yFyes+kgfzYMIC9ZWo4\n",
              "DQMb0AiondlMLjhHs3j/oDlKlQQae4MpEYouSw1aRbOF5GZnMEzmtScWon9PSY/DiHUVIjIqxV14\n",
              "ZF4LkB8TaLOQpuDcrI/7+xFMorYU689p0gVbpoq4TZJNkx3d5vMFblNDNpptH0mkqgdnEzz6EYTc\n",
              "MF7U7UgTO4yD5kAtNQQMyqEiDUN40IJg7L0f5oT8f5u6I+YrabBSdva4mVln0va2qvpFgSzLg6pO\n",
              "N3hITn+0a3zJVO/8mEeA4kfrXRs34/KbY6x61rX+CjFL6fsprazLAmdip9z9uXX/Lv0YVkJ1C4sH\n",
              "foM41UMqxPLfMH04F0bTmV5PrAfchKljfY5xQmRDldWF8c4EVYofK6FkrFP9/PfzL693TeOqisB3\n",
              "vE0MZ59R93EghR0LaZfOCT0MaiabqLLOUWZ5PRokjQMMfiRnhlEspQ60sCxilj9uPPO/bHzZ3Kgu\n",
              "HDec9tZI0YtS5bjprY+vNVtW5v8wIlMU+Mws/HhiKHHj9kTjS46jEMxrCgBnQRwag2vz1Ffyv0/6\n",
              "UQVDJrZk9k6SUbX8h6c7reL2A/C2hLypQU3cZ+TUoJz2iFt5ljvLIhHXard8drRCrUKOVmD9x0MO\n",
              "S4NirOPiu2vRnm1SPb2d5GbQ0MqVIg6DbgwokPVvQ1A8XeXsDNgx68Ot60aahBHrlPJmeUzx+ZC0\n",
              "tta4vgZw9UwCFvuS+mQTpbkS3yP2NPctcmd6nzRWr4cspEH9gNheQo/EpV5NVPwuGNKhe//xdLef\n",
              "HTD97yE3+7LjtxJ/ACKxqf8nDCG1smttNPQKxG4s0PzvAu9E71+kQPSh2yvkP+r0AW3EkJMfSfUY\n",
              "usveb9iB/rDGfSqTL/QuP5u4lD+lGIAAJiEAAANmQZokbEFf/talUAHSgG14AiVYC8MsQGTvvDb1\n",
              "hpCXGxdNAqEqO4UwX4ZAhMr+CNX9tfzqltLn2z7PQiALzeUxv2cGBg7lyviRt3AY1M+bB+1eslLm\n",
              "UQwalkHRvKLdgnqz7El45rrwxMl34NYS8aAr1kom2gffT21Uw+1pgJJSAB9XnC0PIv79fxeNcL4m\n",
              "duftOI7YWWPPf7aEvSls33o0yB/xKUuEhwIIp+OWue3n/vlSCFyQzGpCDEMUjvACAPyvbtUbsnPx\n",
              "A0qe6MNOn4vrtSxxyoDEt55LQz7DeGXkrNmhZ9+BQFwZemIQD5+NmA9qJhdDeV2Nv9hIZNgU4NFJ\n",
              "6nB3veB6e8EfuA3idACSyhoiEdKqvlEz5APhywbnwbAXzSC6SRmRnqE0MnK8DN4VcBQmJxYGHWWf\n",
              "QDmT0V0YGRT8YvJ1hGu/sfOssZPcvqpeaxhlsU3y0N8VPrdxcqFGcKs9UsDUUAB0J0CprrJGQA7j\n",
              "CT1ncNKnx5ehZil3cOsyqp3xzH74eIuAOmUp7k1dT52FKAV251lco5LRAppRYFsgRLffTrjrGRiW\n",
              "wC5oXJBzdxTC3xalROLcQkLLuV4yWr4tqsdFca+9mnfTn6LZlXeTLHM9eveayrSC2Q38IHdo6ju4\n",
              "ZDPpoJpIkxOt2uk6hUczf01Q+2Z/lkzAaxyNcYmrhhT7pxT2Ytvw/OYibSlyKY+0G5JvxG6kK5Eo\n",
              "eDU5cgyo7eEWOwzIrhD/YT1yHAfHjCU8Tr1YaV5d+pOpsR45EEtLX+coCyZ8wWORrS9FVwMSj1Oa\n",
              "ZhT1OJYB+Iq81WdrvpYAaXa3D9z612OMcY3FzIvOkwiX6X378twiDdVCzAy/fNUr/nWcEyHb1lIx\n",
              "8HNfmZEDoSx13C1gTba6xKweKAQWt/ZS6A7B0ZkQiWvswjWsN83libLfPQAX6K8RBvXFX2a7xqhC\n",
              "qPv1aUtjEYpt8B4JJqLlsXS/IwNjxpzDsIyFxBr+kCpnog2dMJBIoHnKNnXz4dPZn1eLuTij87R8\n",
              "Km45oLVgO+P/i7tuLM+3Azron0AqqkOB3kAOnFT/WilTIkkc6YulvZqEu098cYU0Srd10veTwVdl\n",
              "wqzJ5UBB6mJDJUinAfT/MCPc/6AseA3WPxxYdo2zHzf6TYaWwrR0D62CWaKgAAAAR0GeQniCfwAE\n",
              "v4eGFYldaSJFIUUL3/h1zbedEG3xDM4QUp2KWgkMSCdxhV5jZHoYANxjtR1PTmUD7GiB+deSN92i\n",
              "+MUED3OTAAAAKgGeYXRBLwAHDUqNqTY0mjffEb/E38+LSXFxuHADBurhBAPpe8eDXJ5VQAAAAB0B\n",
              "nmNqQS8AAAkpP3amntU16v5iQYtweYJxv25igQAAAdtBmmhJqEFomUwIKf/+1oywAAFlLVQADhr9\n",
              "wqW99HrsEFJY8DfIeAIfO+oAdkE2UV0nqtEClWKjzDsFd7A1lIlzJEXAilQDgknyVwTY3RI715Uy\n",
              "a5MCV6CnnYRj2Q9US4s35zeSFHDewqX9f+wKUH+PEn0uCfigljqsTF8E+q/6gABmFG9XuCOrk8Zr\n",
              "YKXTsiRa5yPTrBEuxQnS9wN9XLRDWi3j2cr3bSUtHYp7/0gQqna843CVwlwPnqol5aeJ9WHh6H1y\n",
              "cC1D/Or1PxD9H+KsnBZrohaRcNTgV+lUNo0vzHkCIldoPsnxGlHfjLz/ELNRYOf2/2HqmZMEh+r+\n",
              "P082tNGNx7TIv3LpV0qh83u+2+YLnxXo9vWWU6c3ySBKmnN9aYe+dLEY8rEXFv0kuQl3sNyXwV/0\n",
              "ft2X7qy9rkn5+iJfllLrQNpaosNDlQhr9Q+QgfqkJPQS2OeBZ933bGE0DFkFA43UcmFkHdmZLEab\n",
              "8kqKubJ2hn++FielQ8NkXppNHXLxnpo1rVy4I4IE4vJ51V1+S8GvZ7OK+yO3TC1boSLyktFKYBFB\n",
              "G7vgFfcEeajo8L1fYIUqBgw1HXwZg5MZwDB0x+0pBdFahZXCe4QPEtWHa37FugsAnyclAAAAJEGe\n",
              "hkURLBP/AAAGKI+CTzHBO9oj6e+USiH2PRzlQGicXTs1YQAAAB4BnqV0QS8AAAkoh3KiEO66p6oB\n",
              "8r31+YEyKGVXlUEAAAAXAZ6nakEvAAAJKT92pqHV7pU4rFgDm+gAAACaQZqpSahBbJlMCCn//taM\n",
              "sAABitzwAAOOpJQGRgcv/9cLUh06Ex24ks7FkrBFMcT793YjrFiguZNqeStnpezXGTUfgXgX8bbc\n",
              "x4l7qi417ZgtlhiS7jIZkMj8eJAKYBzVMf1dYGLhQFDlfgzo41THvcPmSnzYawx27G64Z/7Y+/WA\n",
              "yhIMi7ocmhaVPqTAoy3YTuIdx6yxUIurwAAAAMZBmstJ4QpSZTBRUsFP/taMsAABjCp6RK7fncGA\n",
              "EB5+sDxpKW/jF6URnM1AKYZyw0g8WYC8iHcffcn9YPuOza5EMzEp0le4tzZOmO5lBpeU6vGhozrc\n",
              "xstLg8yu9cGeVmRtQohnq7PrmE9nGAiLOQpGY2ycfy1DeCQkjl5UxUFw0G7GS53pOKdj1bvg2y0c\n",
              "rHlIxmf6ga3JN7dj3b+d8HC65nOjtlMzxirnhS09tDinBTDyaDrgj5GFvSPXDJ5Ex5JHvULL/80A\n",
              "AAAVAZ7qakEvAAADAvqmU0gEoedEYrqAAAAArUGa7UnhDomUwUTBL/61KoAAAW4p5sAG1bw1x0/o\n",
              "HlYBF4LDSwKSSm8wh/hwUtVstZAlvxNIMyq9VAH1JePSrO0ZlmD4ieMEeflYENRjENBrgfHLYdx7\n",
              "FtVOCt+yFt0D+oNTaHw0oqSi9AdeE/jDjQn+odPJQY6qX713renGqkvP2OobF9Szowdyj1YVIh2O\n",
              "rfVcdUgEd5ru/J565BA3vTFFRfne1Aeq+z9e+Xe8AAAAEwGfDGpBLwAAAwC1YgiRa16fN3kAAAPW\n",
              "bW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAFeAAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAA\n",
              "AAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAA\n",
              "AwB0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAFeAAAAAAAAAAAAAAAAAAAAAAAAEA\n",
              "AAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAbAAAAEgAAAAAAAkZWR0cwAAABxlbHN0\n",
              "AAAAAAAAAAEAABXgAAAgAAABAAAAAAJ4bWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAAA4ABV\n",
              "xAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAACI21pbmYA\n",
              "AAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAA\n",
              "AeNzdGJsAAAAs3N0c2QAAAAAAAAAAQAAAKNhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAbAB\n",
              "IABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMWF2\n",
              "Y0MBZAAV/+EAGGdkABWs2UGwloQAAAMACAAAAwAoPFi2WAEABmjr48siwAAAABx1dWlka2hA8l8k\n",
              "T8W6OaUbzwMj8wAAAAAAAAAYc3R0cwAAAAAAAAABAAAADgAAEAAAAAAUc3RzcwAAAAAAAAABAAAA\n",
              "AQAAAIBjdHRzAAAAAAAAAA4AAAABAAAgAAAAAAEAAFAAAAAAAQAAIAAAAAABAAAAAAAAAAEAABAA\n",
              "AAAAAQAAUAAAAAABAAAgAAAAAAEAAAAAAAAAAQAAEAAAAAABAAAgAAAAAAEAADAAAAAAAQAAEAAA\n",
              "AAABAAAwAAAAAAEAABAAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAOAAAAAQAAAExzdHN6AAAAAAAA\n",
              "AAAAAAAOAAAcpwAAA2oAAABLAAAALgAAACEAAAHfAAAAKAAAACIAAAAbAAAAngAAAMoAAAAZAAAA\n",
              "sQAAABcAAAAUc3RjbwAAAAAAAAABAAAALAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAA\n",
              "AAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZm\n",
              "NTcuODMuMTAw\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPVl0raeFmLb",
        "colab_type": "text"
      },
      "source": [
        "## 3D Plot - Optimization process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF8VBRyZFmLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from live_plot import anim_3d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zm0pyS3FmLc",
        "colab_type": "text"
      },
      "source": [
        "__Choose a function below and run the cell__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rGx89ZvFmLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elev, azim = 40, 250\n",
        "x0, y0 = 6, -0.01\n",
        "x_range = torch.arange(-10, 10, 1).float()\n",
        "y_range = torch.arange(-15, 10, 2).float()\n",
        "\n",
        "def function_3d(x, y):\n",
        "    return x ** 2 - y ** 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrpKwKsyFmLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elev, azim = 30, 130\n",
        "x0, y0 = 10, -4\n",
        "x_range = torch.arange(-10, 15, 1).float()\n",
        "y_range = torch.arange(-15, 10, 2).float()\n",
        "\n",
        "def function_3d(x, y):\n",
        "    return x ** 3 - y ** 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBswJrRNFmLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elev, azim = 80, 130\n",
        "x0, y0 = 4, -5\n",
        "x_range = torch.arange(-10, 10, .5).float()\n",
        "y_range = torch.arange(-10, 10, 1).float()\n",
        "\n",
        "def function_3d(x, y):\n",
        "    return (x ** 2 + y ** 2).sqrt().sin()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbTVMAdQFmLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elev, azim = 37, 120\n",
        "x0, y0 = 6, -15\n",
        "x_range = torch.arange(-10, 12, 1).float()\n",
        "y_range = torch.arange(-25, 5, 1).float()\n",
        "\n",
        "# lr 0.15 momentum 0.5\n",
        "def function_3d(x, y):\n",
        "    return (x ** 2 / 20 + x.sin().tanh()) * (y.abs()) ** 1.2 + 5 * x.abs() + (y + 7)**2 / 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX6dBI8ZFmLh",
        "colab_type": "text"
      },
      "source": [
        "__Optimize the function__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX-Ak-qEFmLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = .1\n",
        "iterations = 15\n",
        "\n",
        "x = torch.Tensor([x0]).requires_grad_()\n",
        "y = torch.Tensor([y0]).requires_grad_()\n",
        "optimizer = torch.optim.SGD([x, y], lr=lr)\n",
        "points = []\n",
        "\n",
        "for i in range(iterations):\n",
        "    optimizer.zero_grad()\n",
        "    f = function_3d(x, y)\n",
        "    f.backward()\n",
        "    points += [(x.item(), y.item(), f.item())]\n",
        "    optimizer.step()\n",
        "    \n",
        "anim_3d(x_range, y_range, elev, azim, function_3d, points, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByTUYjvgFmLj",
        "colab_type": "text"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrHGUkSxFmLk",
        "colab_type": "text"
      },
      "source": [
        "<!--NAVIGATION-->\n",
        "# < [Autograd](2-Autograd.ipynb) | Optimization | [Modules](4-Modules.ipynb) >"
      ]
    }
  ]
}